Tutorial
========

.. currentmodule:: hypergol

This guide can help you start working with ``hypergol``. This tutorial assumes you use ``githubcom`` for source control but using other sites must be straightforward as well.

Creating a project
------------------

After installing ``hypergol`` into your virtual environment you are ready to create your first project. Before that create an empty repository on github without ``README.md`` and ``.gitignore``, both will be generated by ``hypergol``. Once created the project the follow the commands there after the ``git init``.

Make sure you are in the directory you intend to create the project into:

.. code:: bash

   $ python3 -m hypergol.cli.create_project <ProjectName>

Project name must be camel-case, and the command will create a snake-case directory. See (insert link here) documentation for creating a project from python interactive shell or from jupyter notebooks.

Once this is done, the next step is to create the project's own virtual environment. This enables encapsulate all the dependencies your project relies on. To do this execute the following steps (Don't forget to ``deactivate`` your current environment):

.. code:: bash

   $ deactivate
   $ cd <project_name>
   $ git init
   $ git commit -m "first commit"
   $ git remote add origin git@github.com:your_user_name/project_name.git
   $ git push -u origin master
   $ ./make_venv.sh
   $ source ./venv/bin/activate

If you have dependencies that you will use in the future (e.g. ``numpy`` add them to ``requirements.txt`` and call:

.. code:: bash

   $ pip3 install -r requirements.txt

Creating a datamodel class
---------------------------

Datamodel is the description of your project's data that your code operates on. It encapsulates your entities and their behaviour. Instead of raw numpy arrays or pandas dataframes, ``hypergol`` stores all data in these classes. This enables to create hierarchical structures and store them in files recursively so you don't need to worry about loading and reloading complex data strucutres. This also helps reasoning and iterating about your code in case you need to change one of the objects and update a pipeline accordingly. Again, see (insert link here) documentation how to create classes from interactive shells.

.. code:: bash

   $ python3 -m hypergol.cli.create_datamodel ExampleClass classId:int:id value:float name:str creation:datetime

This will create the following class (use the ``--dryrun`` switch to display the code instead of writing into ``data_models/example_class.py``

.. code-block:: python

    from datetime import datetime
    from hypergol import BaseData


    class ExampleClass(BaseData):

        def __init__(self, classId: int, name: str, creation: datetime):
            self.classId = classId
            self.name = name
            self.creation = creation

        def get_id(self):
            return (self.classId, )

        def to_data(self):
            data = self.__dict__.copy()
            data['creation'] = data['creation'].isoformat()
            return data

        @classmethod
        def from_data(cls, data):
            data['creation'] = datetime.fromisoformat(data['creation'])
            return cls(**data)

As you can see ``hypergol`` generated the class with the neccessary imports (``datetime``) and the correct serialisation functions into a format that can be `JSON` serialized and saved to disk and back.

Also the ``classId:int:id`` argument's ``id`` field made the field this class's id. It is assumed that this uniquely identifies this class so comparison will happen based on this/these fields. Multiple fields can be marked as ``id`` which will result their tuple to be the id of this class. You not necessary need to specify an id field but only classes with id's can be types of datasets (see later, insert link here) and therefore stored in files, other classes can only be saved if they are part of another id-d class (also known as weak entities). Only ``int`` and ``str`` fields can be marked as ``id``.

Let's see a more complicated example to see hierarchical structures as well.

Again use ``--dryrun`` switch to display the code instead of writing it out. Because this example depends on another datamodel class, ``hypergol`` will check if that class exists and fails if not. So rerun the previous example if you used the ``--dryrun`` switch there.

.. code:: bash

    $ python3 -m hypergol.cli.create_datamodel OtherExample classId:int:id name:str "values:List[ExampleClass]" "times:List[time]"

Don't forget the double quotes or your shell will fail to correctly process the square brackets. This will result in the following code in ``data_models/other_example.py``

.. code-block:: python

    from typing import List
    from datetime import time
    from hypergol import BaseData
    from data_models.example_class import ExampleClass


    class OtherExample(BaseData):

        def __init__(self, classId: int, name: str, values: List[ExampleClass], times: List[time]):
            self.classId = classId
            self.name = name
            self.values = values
            self.times = times

        def get_id(self):
            return (self.classId, )

        def to_data(self):
            data = self.__dict__.copy()
            data['values'] = [v.to_data() for v in data['values']]
            data['times'] = [v.isoformat() for v in data['times']]
            return data

        @classmethod
        def from_data(cls, data):
            data['values'] = [ExampleClass.from_data(v) for v in data['values']]
            data['times'] = [time.fromisoformat(v) for v in data['times']]
            return cls(**data)

As you can see it imports the correct typing class: ``List``, the correct temporal dependency: ``time`` and the correct datamodel dependency: ``data_models.example_class.ExampleClass``. Serialisation and deserialisation of the list is sorted correctly as well.

You can see that in the ``tests/`` directory files were created for each class. ``Hypergol`` automatically create unittests for these classes and enables you to add further ones. You can run the tests by ``./run_tests.sh``. It uses the ``nosetests`` framework and by default verifies the integrity of saving and loading the class which is relevant if you edit the generated code. Once the code is generated you can edit it freely and ``hypergol`` will won't touch it again.

Lets head over to jupyter notebook and investigate how we can store data in ``Datasets``.


