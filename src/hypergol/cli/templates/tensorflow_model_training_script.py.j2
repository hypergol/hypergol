import fire
import tensorflow as tf
from hypergol import Dataset
from hypergol import TensorflowModelManager
from hypergol import ModelOutputPickleSaver

{%- for blockName in blockNames %}
from .blocks.{{ blockName.asSnake }} import {{ blockName.asClass }}
{%- endfor %}
from .{{ modelName.asSnake }} import {{ modelName.asClass }}
from .{{ batchReaderName.asSnake }} import {{ batchReaderName.asClass }}


# SAVE_LOCATION = <save path>

def main():

    # fill in dataset params to load training data
    dataset = Dataset(
        dataType=,
        location=,
        project=,
        branch=,
        name=,
        chunkCount=,
        repoData=
    )

    # fill in batch size
    batchReader = {{ batchReaderName.asClass }}(
        dataset=dataset,
        batchSize=
    )

    # fill in any additional block params
    {%- for blockName in blockNames %}
    {{ blockName.asVariable }} = {{ blockName.asClass }}()
    {%- endfor %}

    model = {{ modelName.asClass }}(
        {%- for blockName in blockNames %}
        {{ blockName.asVariable }}={{ blockName.asVariable }},
        {%- endfor %}
    )

    # optimizer and saving params
    modelManager = TensorflowModelManager(
        model=model,
        optimizer=tf.keras.optimizers.Adam(lr=0.07),
        batchReader=batchReader,
        outputSaver=ModelOutputPickleSaver(savePath=f'{SAVE_LOCATION}/outputs'),
        modelSavePath=f'{SAVE_LOCATION}/checkpoints',
        tensorboardPath=f'{SAVE_LOCATION}/tensorboard',
        saveProtobuf=True,
        restoreVariablesPath=None
    )

    # model training params
    modelManager.run(
        stepCount=1000,
        evaluationSteps=list(range(0, 100, 5)),
        tensorboardSteps=list(range(0, 100, 1)),
        metadataSteps=[0],
        trainingSteps=None
    )


if __name__ == '__main__':
    fire.Fire(main)
